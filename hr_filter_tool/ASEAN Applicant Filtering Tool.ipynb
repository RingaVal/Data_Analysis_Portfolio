{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzUNUw5uwIjQ"
   },
   "source": [
    "# HR Applicant Filtering System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3e11Q_VGqcc"
   },
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "cIJxPuZO63eJ"
   },
   "outputs": [],
   "source": [
    "#@title Installation\n",
    "%%capture\n",
    "import importlib\n",
    "# List of required libraries\n",
    "required_libraries = [\"PyMuPDF\", \"nltk\", \"python-docx\"]\n",
    "\n",
    "# Check if each library is installed, and install if not\n",
    "for lib in required_libraries:\n",
    "    try:\n",
    "        importlib.import_module(lib)\n",
    "        print(f\"{lib} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib} is not installed. Installing...\")\n",
    "        !pip install {lib}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "aCuqRhOz65DY"
   },
   "outputs": [],
   "source": [
    "#@title Libraries\n",
    "%%capture\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.display import FileLink\n",
    "import gdown  # For downloading files from Google Drive\n",
    "from bs4 import BeautifulSoup  # For parsing HTML\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets\n",
    "import gspread\n",
    "from google.colab import auth\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "import fitz\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from docx import Document ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YM9QfBmeQcUN"
   },
   "outputs": [],
   "source": [
    "# @title BLK\n",
    "json_key = {\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "y7XFKqs7Q71g"
   },
   "outputs": [],
   "source": [
    "# @title Authentication/Access\n",
    "# Authenticate with Google Sheets using the JSON key\n",
    "scope_sheets = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds_sheets = ServiceAccountCredentials.from_json_keyfile_dict(json_key, scope_sheets)\n",
    "client_sheets = gspread.authorize(creds_sheets)\n",
    "\n",
    "# Authenticate with Google Drive using the JSON key\n",
    "scope_drive = ['https://www.googleapis.com/auth/drive']\n",
    "creds_drive = service_account.Credentials.from_service_account_info(json_key, scopes=scope_drive)\n",
    "service_drive = build('drive', 'v3', credentials=creds_drive)\n",
    "\n",
    "# Access Google Sheets\n",
    "worksheet_name = \"Sheet2\"\n",
    "worksheet = client_sheets.open('screening_repo').worksheet(worksheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRX3CZysSWZO",
    "outputId": "aa5c69f1-326d-404a-ac78-c417582b0699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'df' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# @title Appending the Dataframe\n",
    "# Check if DataFrame 'df' already exists\n",
    "if 'df' in globals():\n",
    "    print(\"DataFrame 'df' already exists. Skipping...\")\n",
    "else:\n",
    "    # Get all values from the worksheet\n",
    "    rows = worksheet.get_all_values()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows[1:], columns=rows[0])  # Assuming the first row contains column headers\n",
    "    df['Total Score'] = 0\n",
    "    df['Qualification'] = ''\n",
    "    print(\"DataFrame 'df' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFfnTaKDRMEX",
    "outputId": "5c37bc3d-fe09-41e4-a83b-8582497bb532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'dfb' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# @title DFB\n",
    "# Access Google Sheets\n",
    "worksheet_name = \"Asean Applicants\"\n",
    "worksheet2 = client_sheets.open('Initial Screening').worksheet(worksheet_name)\n",
    "\n",
    "\n",
    "# Get all values from the worksheet\n",
    "rows = worksheet2.get_all_values()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "dfb = pd.DataFrame(rows[1:], columns=rows[0])  # Assuming the first row contains column headers\n",
    "\n",
    "print(\"DataFrame 'dfb' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1iAW2ga0SGH",
    "outputId": "79bb7b70-a396-4552-b139-25805c5e0b4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "# @title Renaming columns\n",
    "if \"CV_Link\" in dfb.columns:\n",
    "    print(\"CV_Link already exists. Skipping column renaming...\")\n",
    "else:\n",
    "    # Rename columns by index\n",
    "    dfb.columns.values[1] = 'Name'\n",
    "    dfb.columns.values[2] = 'Email'\n",
    "    dfb.columns.values[3] = 'Employment_Status'\n",
    "    dfb.columns.values[4] = 'Position'\n",
    "    dfb.columns.values[5] = 'Experience'\n",
    "    dfb.columns.values[6] = 'Training_availability'\n",
    "    dfb.columns.values[7] = 'Work_availability'\n",
    "    dfb.columns.values[8] = 'Native_language'\n",
    "    dfb.columns.values[9] = 'English_proficiency'\n",
    "    dfb.columns.values[10] = 'Anytime_training'\n",
    "    dfb.columns.values[11] = 'Device'\n",
    "    dfb.columns.values[12] = 'Backup_device'\n",
    "    dfb.columns.values[13] = 'ISP'\n",
    "    dfb.columns.values[14] = 'Job_post'\n",
    "    dfb.columns.values[15] = 'CV_Link'\n",
    "    dfb.columns.values[16] = 'Shift_adjustments'\n",
    "    dfb.columns.values[17] = 'Dedicated_workspace'\n",
    "    print(\"Columns renamed successfully.\")\n",
    "\n",
    "# Remove leading and trailing whitespace from column names\n",
    "dfb.columns = dfb.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xD5dvoKCSo1S",
    "outputId": "95d8435d-9d92-4807-9727-0389e3f0ef81"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5ff7f335-cf60-4452-a70c-e733e5fec8b0\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Position</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Training_availability</th>\n",
       "      <th>Work_availability</th>\n",
       "      <th>Native_language</th>\n",
       "      <th>English_proficiency</th>\n",
       "      <th>...</th>\n",
       "      <th>CV_Link</th>\n",
       "      <th>Shift_adjustments</th>\n",
       "      <th>Dedicated_workspace</th>\n",
       "      <th></th>\n",
       "      <th>Remarks</th>\n",
       "      <th>Status</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>08/05/2024 00:06:49</td>\n",
       "      <td>LIM ZE KAI</td>\n",
       "      <td>flyx3jet97@gmail.com</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Data Analyst (Chinese)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chinese /Mandarin</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>...</td>\n",
       "      <td>https://drive.google.com/open?id=1eQThgCGfL5qj...</td>\n",
       "      <td>Option 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Invalid File Format/No Access</td>\n",
       "      <td>,, chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10/05/2024 10:03:55</td>\n",
       "      <td>GAN HUI YI</td>\n",
       "      <td>huiyigan1222@gmail.com</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Data Analyst (Chinese)</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chinese /Mandarin</td>\n",
       "      <td>Proficient</td>\n",
       "      <td>...</td>\n",
       "      <td>https://drive.google.com/open?id=1L-Dn-_sFC2ZG...</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>GAN HUI YI\\n+60176360135\\nhuiyigan1222@gmail.c...</td>\n",
       "      <td>january, kong, formatting, functions, johor, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>16/05/2024 18:14:56</td>\n",
       "      <td>Nur Faqihah binti Zulkapeli</td>\n",
       "      <td>nurfaqizul431997@gmail.com</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Data Analyst (Malay or Bahasa Malaysia)</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Malay</td>\n",
       "      <td>Proficient</td>\n",
       "      <td>...</td>\n",
       "      <td>https://drive.google.com/open?id=1VoVhgBoaeGdO...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Invalid File Format/No Access</td>\n",
       "      <td>malay, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>17/05/2024 17:17:23</td>\n",
       "      <td>Shakthi Maheshvari</td>\n",
       "      <td>shakthi16092001@gmail.com</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Data Analyst (Tamil)</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Proficient</td>\n",
       "      <td>...</td>\n",
       "      <td>https://drive.google.com/open?id=1A7RMsJAdOLR3...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>`  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\...</td>\n",
       "      <td>dax, database, managed, committed, sla, solvin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>29/05/2024 22:28:34</td>\n",
       "      <td>Leerwinash Raja A/L Raja Rajandran</td>\n",
       "      <td>winash451@gmail.com</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Data Analyst (Malay or Bahasa Malaysia)</td>\n",
       "      <td>Extensive</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>...</td>\n",
       "      <td>https://drive.google.com/open?id=1orKDj16LLp9l...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>LEERWINASH RAJA A/L RAJA RAJANDRAN\\n23 YEARS O...</td>\n",
       "      <td>system, css, word, references, permaisuri, jul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ff7f335-cf60-4452-a70c-e733e5fec8b0')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5ff7f335-cf60-4452-a70c-e733e5fec8b0 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5ff7f335-cf60-4452-a70c-e733e5fec8b0');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-511522ec-f657-40cd-944c-ec00a98f80c9\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-511522ec-f657-40cd-944c-ec00a98f80c9')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-511522ec-f657-40cd-944c-ec00a98f80c9 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              Timestamp                                Name  \\\n",
       "89  08/05/2024 00:06:49                          LIM ZE KAI   \n",
       "90  10/05/2024 10:03:55                          GAN HUI YI   \n",
       "91  16/05/2024 18:14:56         Nur Faqihah binti Zulkapeli   \n",
       "92  17/05/2024 17:17:23                 Shakthi Maheshvari    \n",
       "93  29/05/2024 22:28:34  Leerwinash Raja A/L Raja Rajandran   \n",
       "\n",
       "                         Email Employment_Status  \\\n",
       "89        flyx3jet97@gmail.com        Unemployed   \n",
       "90      huiyigan1222@gmail.com        Unemployed   \n",
       "91  nurfaqizul431997@gmail.com        Unemployed   \n",
       "92   shakthi16092001@gmail.com        Unemployed   \n",
       "93         winash451@gmail.com        Unemployed   \n",
       "\n",
       "                                   Position Experience Training_availability  \\\n",
       "89                   Data Analyst (Chinese)        Yes                   Yes   \n",
       "90                   Data Analyst (Chinese)         No                   Yes   \n",
       "91  Data Analyst (Malay or Bahasa Malaysia)   Moderate                   Yes   \n",
       "92                     Data Analyst (Tamil)   Moderate                   Yes   \n",
       "93  Data Analyst (Malay or Bahasa Malaysia)  Extensive                   Yes   \n",
       "\n",
       "   Work_availability    Native_language English_proficiency  ...  \\\n",
       "89               Yes  Chinese /Mandarin              Fluent  ...   \n",
       "90               Yes  Chinese /Mandarin          Proficient  ...   \n",
       "91               Yes              Malay          Proficient  ...   \n",
       "92               Yes              Tamil          Proficient  ...   \n",
       "93               Yes              Tamil              Fluent  ...   \n",
       "\n",
       "                                              CV_Link Shift_adjustments  \\\n",
       "89  https://drive.google.com/open?id=1eQThgCGfL5qj...          Option 1   \n",
       "90  https://drive.google.com/open?id=1L-Dn-_sFC2ZG...               Yes   \n",
       "91  https://drive.google.com/open?id=1VoVhgBoaeGdO...               Yes   \n",
       "92  https://drive.google.com/open?id=1A7RMsJAdOLR3...               Yes   \n",
       "93  https://drive.google.com/open?id=1orKDj16LLp9l...               Yes   \n",
       "\n",
       "   Dedicated_workspace   Remarks Status Total Score Qualification  \\\n",
       "89                                              0.0                 \n",
       "90                                              0.0                 \n",
       "91                 Yes                          0.0                 \n",
       "92                 Yes                          0.0                 \n",
       "93                 Yes                          0.0                 \n",
       "\n",
       "                                                 Text  \\\n",
       "89                      Invalid File Format/No Access   \n",
       "90  GAN HUI YI\\n+60176360135\\nhuiyigan1222@gmail.c...   \n",
       "91                      Invalid File Format/No Access   \n",
       "92  `  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\...   \n",
       "93  LEERWINASH RAJA A/L RAJA RAJANDRAN\\n23 YEARS O...   \n",
       "\n",
       "                                          CleanedText  \n",
       "89                                         ,, chinese  \n",
       "90  january, kong, formatting, functions, johor, e...  \n",
       "91                                           malay, ,  \n",
       "92  dax, database, managed, committed, sla, solvin...  \n",
       "93  system, css, word, references, permaisuri, jul...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Appending New Rows\n",
    "# Left merge dataframes dfb and df on the \"CV_Link\" column\n",
    "merged_df = pd.merge(dfb, df[['CV_Link', 'Total Score', 'Qualification', 'Text', 'CleanedText']],\n",
    "                     on='CV_Link', how='left')\n",
    "\n",
    "# Fill NaN values with the desired values\n",
    "merged_df['Total Score'].fillna(0, inplace=True)\n",
    "merged_df['Qualification'].fillna('', inplace=True)\n",
    "merged_df['Text'].fillna('', inplace=True)\n",
    "merged_df['CleanedText'].fillna('', inplace=True)\n",
    "\n",
    "# Drop rows with empty values in the \"CV_Link\" column\n",
    "merged_df.dropna(subset=['CV_Link'], inplace=True)\n",
    "\n",
    "# Filter out rows with empty strings in the \"CV_Link\" column\n",
    "merged_df = merged_df[merged_df['CV_Link'] != '']\n",
    "\n",
    "# Drop rows in the \"Status\" column that contain strings\n",
    "merged_df = merged_df[~merged_df['Status'].str.contains('[a-zA-Z]')]\n",
    "\n",
    "# Reset index\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "vYBE-M921IQk"
   },
   "outputs": [],
   "source": [
    "# @title GDrive Engine\n",
    "# Define the function for batch processing to download and extract text\n",
    "def batch_download_and_extract_text(service, urls):\n",
    "    texts = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Extract file ID from the URL\n",
    "            file_id = url.split('=')[-1]\n",
    "\n",
    "            # Retrieve metadata to get the file name\n",
    "            file_metadata = service.files().get(fileId=file_id, fields=\"name\").execute()\n",
    "            filename = file_metadata['name']\n",
    "\n",
    "            # Download the file\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "            fh = BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "            done = False\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "\n",
    "            fh.seek(0)\n",
    "\n",
    "            # Extract text based on file type\n",
    "            _, file_extension = os.path.splitext(filename)\n",
    "            if file_extension.lower() == '.pdf':\n",
    "                # Extract text from the PDF file using PyMuPDF (fitz)\n",
    "                text = \"\"\n",
    "                with fitz.open(stream=fh, filetype=\"pdf\") as pdf_doc:\n",
    "                    for page_num in range(len(pdf_doc)):\n",
    "                        page = pdf_doc.load_page(page_num)\n",
    "                        text += page.get_text()\n",
    "            elif file_extension.lower() in ['.docx', '.doc']:\n",
    "                # Extract text from the DOCX or DOC file using python-docx\n",
    "                doc = Document(fh)\n",
    "                text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "            else:\n",
    "                # Unsupported file type\n",
    "                print(f\"Unsupported file type for URL: {url}\")\n",
    "                text = \"Invalid File Format/No Access\"\n",
    "\n",
    "            if not text.strip():\n",
    "                text = \"Invalid File Format/No Access\"\n",
    "\n",
    "            texts.append(text)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while downloading or extracting text from the file: {e}\")\n",
    "            texts.append(\"Invalid File Format/No Access\")\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw0fKmBP5uh1",
    "outputId": "ace0ef59-38fe-421b-f77b-5c0ecac3fad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Updated\n"
     ]
    }
   ],
   "source": [
    "# @title Reading the CVs\n",
    "\n",
    "# Check if there is any empty string in the \"CleanedText\" column\n",
    "if (merged_df[\"CleanedText\"].str.strip() == '').any():\n",
    "    # Filter the DataFrame to get only the rows with empty strings in the \"CleanedText\" column\n",
    "    filtered_df = merged_df[merged_df[\"CleanedText\"].str.strip() == '']\n",
    "\n",
    "    # Extract the URLs from the filtered DataFrame\n",
    "    urls = filtered_df[\"CV_Link\"].tolist()\n",
    "\n",
    "    # Use ThreadPoolExecutor to perform parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks for batch processing\n",
    "        future = executor.submit(batch_download_and_extract_text, service_drive, urls)\n",
    "        texts = future.result()\n",
    "\n",
    "    # Assign extracted text to the \"Text\" column in the filtered DataFrame\n",
    "    filtered_df[\"Text\"] = texts\n",
    "\n",
    "    # Update the original DataFrame with the updated values from the filtered DataFrame\n",
    "    merged_df.update(filtered_df)\n",
    "\n",
    "else:\n",
    "    # Print all updated DataFrame\n",
    "    print(\"All Updated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3vxdNvFhGXx"
   },
   "source": [
    "## Applicant Shortlisting Tool\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. Input the necessary information such as <font color=\"orange\"><b>Job Title</b></font>, <font color=\"green\"><b>Job Description</b></font>, <font color=\"red\"><b>Foreign Language</b></font>, and <font color=\"yellow\"><b>Supplementary Keywords</b></font>  in the designated fields below.\n",
    "\n",
    "2. Press **Connect** at the upper right corner. <font color=\"green\"><b>Wait for a green check mark to appear</b></font>.\n",
    "\n",
    "3. Click **Runtime** dropdown and click **Run All** to run the notebook. A prompt will appear but just click \"Run Anyway\". Each run takes about less than 2 minutes.\n",
    "\n",
    "4. You can change your entries in the Job Title, Job Description, etc. fields and run it again by following **Step 3**.\n",
    "\n",
    "4. Scroll down to view the shortlist at the bottom. You can manipulate it to show different Job Positions by clicking on the \"**Select Position**\" dropdown button. Other filters are also available.\n",
    "\n",
    "5. Scroll sideward to reveal more information about the applicants. Can now also be viewed in Fullscreen (See documentation).\n",
    "\n",
    "6. You can also export your chosen shortlist into an Excel file by clicking the \"**Export as Excel File**\" button. It is at the bottom of the shortlist.\n",
    "\n",
    "7. Click the little Folder icon on the left side to open up the window pane. Download the file by right clicking and choosing download.\n",
    "\n",
    "9. If an error pops-up. Refresh the page itself. Refreshing the page would need you to enter the necessary fields again.\n",
    "\n",
    "10. For persistent errors, contact the notebook owner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ExA95eR9G-Y3"
   },
   "outputs": [],
   "source": [
    "#@title <font color='Orange'>Job Title </font>\n",
    "job_post = \"\"# @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "AiojQmPVEXwK"
   },
   "outputs": [],
   "source": [
    "#@title <font color='Green'>Job Description </font>\n",
    "user_input = \"\"# @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "84GBm-IUyBf6"
   },
   "outputs": [],
   "source": [
    "#@title  <font color='Red'> Foreign Language </font> (dont put English)\n",
    "Qualifying_keywords = \"\"# @param {type: \"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "K2qAmnLbx96E"
   },
   "outputs": [],
   "source": [
    "#@title <font color='yellow'>  Supplementary Keywords </font>\n",
    "supplementary_keywords = \"\"# @param {type: \"string\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NioUnIPmFXSt"
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7uD7tljE8zP",
    "outputId": "e886009c-c384-423d-cbcd-7369d6a8e1d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Updated\n"
     ]
    }
   ],
   "source": [
    "#@title Tokenization\n",
    "\n",
    "\n",
    "# Define the list of negative words\n",
    "negative_words = [\"degree\", \"proficiency\", \"exceptional\", \"proven\", \"experience\", \"strong\", \"skills\", \"city\", \"university\",\n",
    "                  \"2023\",\"2024\", \"management\", \"2022\", \"customer\", \"school\", \"philippines\",\n",
    "                  \"ability\", \"interpret\", \"complex\", \"information\", \"excellent\",\n",
    "                  \"work\", \"effectively\", \"proficiency\", \"utilizing\", \"various\",\n",
    "                  \"conduct\", \"in-depth\", \"research\", \"across\", \"diverse\", \"sources\",\n",
    "                  \"gather\", \"relevant\", \"data\", \"evaluate\", \"credibility\", \"relevancy\",\n",
    "                  \"obtained\", \"different\", \"translate\", \"synthesize\", \"comprehensive\",\n",
    "                  \"english\", \"reports\", \"maintaining\", \"accuracy\", \"clarity\",\n",
    "                  \"decision-making\", \"processes\", \"stay\", \"updated\", \"changes\",\n",
    "                  \"global\", \"markets\", \"ensure\", \"accuracy\", \"relevance\", \"reports\",\n",
    "                  \"utilize\", \"enhance\", \"analysis\", \"processes\", \"knowledge\",\n",
    "                  \"familiarity\", \"understands\", \"intricacies\", \"platforms\",\n",
    "                  \"familiarity\", \"identify\", \"filter\", \"irrelevant\", \"posts\",\n",
    "                  \"assess\", \"summarize\", \"comments\", \"made\", \"posts\", \"access\", \"file\", \"invalid\",\n",
    "                  \"group\", \"structure\", \"predefined\", \"criteria\", \"topics\",\n",
    "                  \"good\", \"eg\", \"etc\", \"Main\", \"task\", \"tasks\", 'include', 'required', 'skills', 'other']\n",
    "\n",
    "# Check if there is any empty string in the \"CleanedText\" column\n",
    "if (merged_df[\"CleanedText\"].str.strip() == '').any():\n",
    "    # Filter the DataFrame to get only the rows with empty strings in the \"CleanedText\" column\n",
    "    filtered_df2 = merged_df[merged_df[\"CleanedText\"].str.strip() == '']\n",
    "\n",
    "    # Define function to remove numbers from text\n",
    "    def remove_numbers(text):\n",
    "        if isinstance(text, str):\n",
    "            return re.sub(r'\\d+', '', text)\n",
    "        else:\n",
    "            return str(text)\n",
    "\n",
    "    # Apply text cleaning functions to the 'Text' and 'Specify your skills relevant to the position you are applying for.' columns\n",
    "    filtered_df2['CleanedText'] = filtered_df2['Text'].apply(lambda x: ', '.join([word for word in word_tokenize(x.lower()) if len(word) > 1 and word.isalnum() and word.lower() not in stopwords.words('english')]))\n",
    "    filtered_df2['CleanedSkills'] = filtered_df2['Native_language'].apply(lambda x: ', '.join([word for word in word_tokenize(x.lower()) if len(word) > 1 and word.isalnum() and word.lower() not in stopwords.words('english')]))\n",
    "\n",
    "    # Remove negative words from CleanedText\n",
    "    filtered_df2['CleanedText'] = filtered_df2['CleanedText'].apply(lambda x: ' '.join([word for word in word_tokenize(x.lower()) if word.lower() not in negative_words]))\n",
    "\n",
    "    # Combine CleanedText and CleanedSkills, remove duplicates, and join back into a string\n",
    "    filtered_df2['CleanedText'] = (filtered_df2['CleanedText'] + ', ' + filtered_df2['CleanedSkills']).apply(lambda x: ', '.join(set(word_tokenize(x))))\n",
    "\n",
    "    # Update the merged_df with the cleaned data\n",
    "    merged_df.update(filtered_df2)\n",
    "\n",
    "else:\n",
    "    # Print all updated DataFrame\n",
    "    print(\"All Updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0p2REaowxxKj"
   },
   "outputs": [],
   "source": [
    "#@title Process 1\n",
    "\n",
    "input_tokens = set(word_tokenize(user_input.lower()))\n",
    "\n",
    "pd2 = pd.DataFrame({\"UserInput\": list(input_tokens)})\n",
    "\n",
    "pd2 = pd.merge(pd2, pd.DataFrame({\"NegativeWords\": negative_words}), how=\"left\", left_on=\"UserInput\", right_on=\"NegativeWords\")\n",
    "\n",
    "pd2_cleaned = pd2[pd2['NegativeWords'].isna()].drop(columns=['NegativeWords'])\n",
    "\n",
    "cleaned_list = ', '.join(pd2_cleaned['UserInput'])\n",
    "cleaned_list = re.sub(r'[^a-zA-Z0-9\\s]', '', cleaned_list)\n",
    "cleaned_tokens = word_tokenize(cleaned_list)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "cleaned_tokens = [word for word in cleaned_tokens if word.lower() not in stop_words]\n",
    "\n",
    "df2 = pd.DataFrame({\"CleanedList\": [', '.join(cleaned_tokens)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "mbiowtoUffCd"
   },
   "outputs": [],
   "source": [
    "#@title Process 2\n",
    "\n",
    "\n",
    "supplementary_tokens = set(word_tokenize(supplementary_keywords.lower()))\n",
    "\n",
    "df3 = pd.DataFrame({\"SupplementaryKeywords\": list(supplementary_tokens)})\n",
    "\n",
    "df3['SupplementaryKeywords'] = df3['SupplementaryKeywords'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df3['SupplementaryKeywords'] = df3['SupplementaryKeywords'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "D5F9PPiyTX0K"
   },
   "outputs": [],
   "source": [
    "#@title Process 3\n",
    "\n",
    "# Function to preprocess QualifyingKeywords\n",
    "def preprocess_keywords(keywords):\n",
    "    # Split words separated by slash\n",
    "    keywords_split = re.split(r'[/\\s,]+', keywords)\n",
    "    # Tokenize each word and convert to lowercase\n",
    "    tokens = [word_tokenize(word.lower()) for word in keywords_split]\n",
    "    # Flatten the list of tokens\n",
    "    flattened_tokens = [token for sublist in tokens for token in sublist]\n",
    "    return flattened_tokens\n",
    "\n",
    "# Apply preprocessing to QualifyingKeywords\n",
    "Qualifying_tokens = preprocess_keywords(Qualifying_keywords)\n",
    "\n",
    "# Create a set of preprocessed QualifyingKeywords tokens\n",
    "Qualifying_tokens_set = set(Qualifying_tokens)\n",
    "\n",
    "# Create DataFrame with QualifyingKeywords tokens\n",
    "df4 = pd.DataFrame({\"QualifyingKeywords\": list(Qualifying_tokens_set)})\n",
    "\n",
    "# Remove special characters\n",
    "df4['QualifyingKeywords'] = df4['QualifyingKeywords'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df4['QualifyingKeywords'] = df4['QualifyingKeywords'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XPOpa6C___3_"
   },
   "outputs": [],
   "source": [
    "#@title Hardware Reqts\n",
    "\n",
    "\n",
    "# Function to extract RAM, storage, and processor information from a string\n",
    "def extract_specs(specs_text):\n",
    "    ram = None\n",
    "    storage = None\n",
    "    processor = None\n",
    "\n",
    "    # Extract RAM using regex\n",
    "    ram_match = re.search(r'(\\d+)\\s*(?:GB|gb|Gb)\\s*RAM', specs_text)\n",
    "    if ram_match:\n",
    "        ram = int(ram_match.group(1))\n",
    "    elif '8gb' in specs_text.lower() or '8 gb' in specs_text.lower():\n",
    "        ram = 8\n",
    "\n",
    "    # Extract storage using regex\n",
    "    storage_match = re.search(r'(\\d+)\\s*(?:GB|gb|Gb|TB|tb|Tb)\\s*storage', specs_text)\n",
    "    if storage_match:\n",
    "        storage = int(storage_match.group(1))\n",
    "    elif '256gb' in specs_text.lower() or '256 gb' in specs_text.lower():\n",
    "        storage = 256\n",
    "\n",
    "    # Extract processor using regex\n",
    "    processor_match = re.search(r'(?:Intel|AMD|Ryzen|Macbook|M1|m2|m3).*?(?:i\\d|core)', specs_text, re.IGNORECASE)\n",
    "    if processor_match:\n",
    "        processor = processor_match.group()\n",
    "    elif 'i7' in specs_text.lower():\n",
    "        processor = 'i7'\n",
    "    elif 'ryzen' in specs_text.lower():\n",
    "        processor = 'Ryzen'\n",
    "    elif 'macbook' in specs_text.lower():\n",
    "        processor = 'Macbook'\n",
    "\n",
    "    return ram, storage, processor\n",
    "\n",
    "# Function to check if any specs information is present\n",
    "def has_specs(specs_text):\n",
    "    ram, storage, processor = extract_specs(specs_text)\n",
    "    return ram is not None or storage is not None or processor is not None\n",
    "\n",
    "# Create new column 'extracted_specs'\n",
    "merged_df['extracted_specs'] = merged_df['Device'].apply(has_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FhnHrtlEIWjt"
   },
   "outputs": [],
   "source": [
    "#@title ISP Reqts\n",
    "\n",
    "# Function to check if internet speed meets the criteria\n",
    "def extract_isp(isp_text):\n",
    "    # Define a pattern to match various misspellings and abbreviations of \"Mbps\"\n",
    "    pattern = r'\\b(\\d+(\\.\\d+)?)\\s*(?:mbps?|mbs?|mpbs?|mbsp?|gsbps?|gsbs?|gsb|mb)\\b'\n",
    "\n",
    "    # Extract numerical values from the text\n",
    "    numbers = [float(num[0]) for num in re.findall(r'\\b(\\d+(\\.\\d+)?)\\b', isp_text.lower())]\n",
    "\n",
    "    # If there are two numerical values, compare them and then compare with 30\n",
    "    if len(numbers) >= 2:\n",
    "        max_speed = max(numbers)\n",
    "        if max_speed >= 30:\n",
    "            return True\n",
    "    # If there's only one numerical value, compare with 30\n",
    "    elif len(numbers) == 1:\n",
    "        if numbers[0] >= 30:\n",
    "            return True\n",
    "\n",
    "    # Check if any numeric value from the original function is greater than or equal to 30\n",
    "    numeric_values = re.findall(pattern, isp_text.lower())\n",
    "    if any(float(value[0]) >= 30 for value in numeric_values):\n",
    "        return True\n",
    "    # Check for specific keywords indicating high-speed internet\n",
    "    elif any(speed in isp_text.lower() for speed in ['gigabit', 'gbps', '5g', '4g']):\n",
    "        return True\n",
    "    # Check for separate download and upload speeds\n",
    "    elif 'download' in isp_text.lower():\n",
    "        download_speed_match = re.search(r'download\\s*(\\d+(\\.\\d+)?)', isp_text.lower())\n",
    "        if download_speed_match:\n",
    "            download_speed = float(download_speed_match.group(1))\n",
    "            if download_speed >= 30:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Create new column 'extracted_isp'\n",
    "merged_df['extracted_isp'] = merged_df['ISP'].apply(extract_isp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BKofFRGPNMgw"
   },
   "outputs": [],
   "source": [
    "#@title Scoring\n",
    "\n",
    "\n",
    "def calculate_score(row):\n",
    "    total_score = 0\n",
    "\n",
    "    cleaned_text_tokens = set(row['CleanedText'].split(', '))\n",
    "\n",
    "    if 'CleanedList' in df2.columns and df2['CleanedList'].dtype == 'object':\n",
    "        total_score += len(set(cleaned_text_tokens) & set(df2['CleanedList'].str.split(', ').explode().unique()))\n",
    "\n",
    "    if 'SupplementaryKeywords' in df3.columns and df3['SupplementaryKeywords'].dtype == 'object':\n",
    "        total_score += len(set(cleaned_text_tokens) & set(df3['SupplementaryKeywords'].str.split(', ').explode().unique()))\n",
    "\n",
    "    if 'QualifyingKeywords' in df4.columns and df4['QualifyingKeywords'].dtype == 'object':\n",
    "        total_score += len(set(cleaned_text_tokens) & set(df4['QualifyingKeywords'].str.split(', ').explode().unique()))\n",
    "\n",
    "    return total_score\n",
    "\n",
    "merged_df['Total Score'] = merged_df.apply(calculate_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XF8c80lToDyt"
   },
   "outputs": [],
   "source": [
    "#@title Qualification\n",
    "\n",
    "def determine_qualification(row):\n",
    "    cleaned_text_tokens = set(row['CleanedText'].split(', '))\n",
    "    not_qualified_reasons = []\n",
    "\n",
    "    if 'Anytime_training' in row.index and row['Anytime_training'] != 'Yes':\n",
    "        not_qualified_reasons.append(\"Training availability\")\n",
    "\n",
    "    if 'Backup_device' in row.index and row['Backup_device'] != 'Yes':\n",
    "        not_qualified_reasons.append(\"Backup device\")\n",
    "\n",
    "    if not row.get('extracted_specs', False):\n",
    "        not_qualified_reasons.append(\"Hardware specs\")\n",
    "\n",
    "    if not row.get('extracted_isp', False):\n",
    "        not_qualified_reasons.append(\"ISP\")\n",
    "\n",
    "    if row.get('Experience', '') in ('No', ''):\n",
    "        not_qualified_reasons.append(\"Experience\")\n",
    "\n",
    "    if ('Anytime_training' in row.index and row['Anytime_training'] == 'Yes' and\n",
    "        'Backup_device' in row.index and row['Backup_device'] == 'Yes' and\n",
    "        row.get('extracted_specs', False) and\n",
    "        row.get('extracted_isp', False) and\n",
    "        row.get('Experience', '') not in ('No', '')):\n",
    "        if 'QualifyingKeywords' in df4.columns and df4['QualifyingKeywords'].dtype == 'object':\n",
    "            qualifying_keywords_tokens = set(df4['QualifyingKeywords'].str.split(', ').explode().unique())\n",
    "\n",
    "            if set(cleaned_text_tokens) & qualifying_keywords_tokens:\n",
    "                return \"Qualified\"\n",
    "            else:\n",
    "                if not_qualified_reasons:\n",
    "                    return \"Not Qualified: \" + ', '.join(not_qualified_reasons)\n",
    "                else:\n",
    "                    return \"Not Qualified\"\n",
    "    else:\n",
    "        if not_qualified_reasons:\n",
    "            return \"Not Qualified: \" + ', '.join(not_qualified_reasons)\n",
    "        else:\n",
    "            return \"Not Qualified\"\n",
    "\n",
    "# Apply determine_qualification function to each row of merged_df\n",
    "merged_df['Qualification'] = merged_df.apply(determine_qualification, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "4rTwGFKKqMJg"
   },
   "outputs": [],
   "source": [
    "#@title Computation\n",
    "\n",
    "qualified_df = merged_df[merged_df['Qualification'] == 'Qualified']\n",
    "\n",
    "qualified_df = qualified_df.sort_values(by='Total Score', ascending=False)\n",
    "\n",
    "not_qualified_df = merged_df[merged_df['Qualification'].isin(['N/A', 'Not Qualified'])]\n",
    "\n",
    "not_qualified_df = not_qualified_df.sort_values(by='Total Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Av_CpeSckfUj",
    "outputId": "8c8fa6c6-707c-444c-ee6a-dfc685ea5ac6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-ea7f8315d524>:22: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet3.update('A1', values_with_headers)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1PS782vFp9eXtSKkkknre4-XzM0_XJoWXER7zPwaxNNw',\n",
       " 'updatedRange': 'Sheet2!A1:Z95',\n",
       " 'updatedRows': 95,\n",
       " 'updatedColumns': 26,\n",
       " 'updatedCells': 2470}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Saving\n",
    "\n",
    "# Drop columns with empty names\n",
    "merged_df = merged_df.drop(columns=['' for col in merged_df.columns if col == ''])\n",
    "\n",
    "# Open the existing Google Sheet named \"screening_repo\"\n",
    "sheet3 = client_sheets.open('screening_repo')\n",
    "\n",
    "# Select the first (default) worksheet\n",
    "worksheet3 = sheet3.get_worksheet(1)\n",
    "\n",
    "# Clear the contents of the worksheet\n",
    "worksheet3.clear()\n",
    "\n",
    "# Get the column headers\n",
    "headers = merged_df.columns.tolist()\n",
    "\n",
    "# Convert DataFrame to a list of lists, including headers\n",
    "values_with_headers = [headers] + merged_df.fillna('').values.tolist()\n",
    "\n",
    "# Update the values in the worksheet\n",
    "worksheet3.update('A1', values_with_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NFZ3Bn4Nm4I"
   },
   "source": [
    "## Shortlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "h6MHpPA6maZQ"
   },
   "outputs": [],
   "source": [
    "#@title Filtered Applicants\n",
    "\n",
    "# Function to sanitize a string for use in filenames\n",
    "def sanitize_for_filename(string):\n",
    "    # Replace invalid characters with underscores\n",
    "    sanitized_string = re.sub(r'[\\\\/*?:\"<>|]', '_', string)\n",
    "    return sanitized_string\n",
    "\n",
    "# Convert \"Timestamp\" column to datetime\n",
    "merged_df['Timestamp'] = pd.to_datetime(merged_df['Timestamp'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Format months in \"Timestamp\" column as month names\n",
    "merged_df['Month'] = merged_df['Timestamp'].dt.strftime('%B')  # '%B' gives full month name\n",
    "\n",
    "# Columns to hide from the output\n",
    "columns_to_hide = [\"Text\", \"CleanedText\",\"extracted_specs\",\"extracted_isp\"]\n",
    "\n",
    "# Default values for dropdowns\n",
    "def set_default_values():\n",
    "    default_employment_status = \"Unemployed\"\n",
    "    default_work = \"Yes\"\n",
    "    # Removed setting default year since year dropdown is removed\n",
    "\n",
    "    employment_status_dropdown.value = default_employment_status\n",
    "    work_dropdown.value = default_work\n",
    "    # Removed setting default year since year dropdown is removed\n",
    "\n",
    "# Create dropdown widgets for unique positions\n",
    "unique_positions = merged_df[\"Position\"].unique()\n",
    "position_dropdown = widgets.Dropdown(options=unique_positions, description='Select Position:')\n",
    "\n",
    "# Custom display function to format the DataFrame output\n",
    "def update_dropdowns(*args):\n",
    "    try:\n",
    "        filtered_df = merged_df[merged_df[\"Position\"] == position_dropdown.value]\n",
    "        unique_statuses = filtered_df[\"Employment_Status\"].unique()\n",
    "        unique_language = filtered_df[\"Native_language\"].unique()\n",
    "        unique_work = filtered_df[\"Work_availability\"].unique()\n",
    "        unique_proficiency = filtered_df[\"English_proficiency\"].unique()\n",
    "        # Removed updating unique years and months since year and month dropdowns are removed\n",
    "\n",
    "        employment_status_dropdown.options = unique_statuses\n",
    "        language_dropdown.options = unique_language\n",
    "        work_dropdown.options = unique_work\n",
    "        proficiency_dropdown.options = unique_proficiency\n",
    "        # Removed updating options for year and month dropdowns\n",
    "\n",
    "        set_default_values()\n",
    "    except Exception as e:\n",
    "        pass  # Suppress any errors\n",
    "\n",
    "# Link dropdown widgets to update function\n",
    "position_dropdown.observe(update_dropdowns, 'value')\n",
    "\n",
    "# Create dropdown widgets for dependent options\n",
    "employment_status_dropdown = widgets.Dropdown(description='Employment Status:')\n",
    "language_dropdown = widgets.Dropdown(description='Native_language:')\n",
    "work_dropdown = widgets.Dropdown(description='Work_availability:')\n",
    "proficiency_dropdown = widgets.Dropdown(description='English_proficiency:')\n",
    "# Removed creation of year and month dropdowns\n",
    "\n",
    "# Dropdown for Total Score filter\n",
    "score_filter_dropdown = widgets.Dropdown(options=[\"Above or Equal to 10\", \"Below 10\"], description='Total Score Filter:')\n",
    "\n",
    "# Call update function initially to set initial options\n",
    "update_dropdowns()\n",
    "\n",
    "# Specify columns to hide from the output\n",
    "columns_to_hide = [\"Text\", \"CleanedText\",\"extracted_specs\",\"extracted_isp\"]\n",
    "\n",
    "# Custom display function to format the DataFrame output\n",
    "def display_dataframe(position, employment_status, language, work, proficiency, score_filter):\n",
    "    try:\n",
    "        filtered_df = merged_df[(merged_df[\"Position\"] == position) &\n",
    "                                (merged_df[\"Employment_Status\"] == employment_status) &\n",
    "                                (merged_df[\"Native_language\"] == language) &\n",
    "                                (merged_df[\"Work_availability\"] == work) &\n",
    "                                (merged_df[\"English_proficiency\"] == proficiency)]\n",
    "                                # Removed filtering by year and month\n",
    "\n",
    "        if score_filter == \"Above or Equal to 10\":\n",
    "            filtered_df = filtered_df[filtered_df['Total Score'] >= 10]\n",
    "        elif score_filter == \"Below 10\":\n",
    "            filtered_df = filtered_df[filtered_df['Total Score'] < 10]\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            display(HTML(\"<p style='font-size:20px; font-weight:bold;'>No applicants meet the criteria.</p>\"))\n",
    "            return\n",
    "\n",
    "        sorted_df = filtered_df.sort_values(by=\"Total Score\", ascending=False)\n",
    "        total_score = sorted_df.pop(\"Total Score\")\n",
    "        qualification = sorted_df.pop(\"Qualification\")\n",
    "\n",
    "        display_df = sorted_df.drop(columns_to_hide, axis=1)\n",
    "        display_df.insert(0, \"Total Score\", total_score)\n",
    "        display_df.insert(1, \"Qualification\", qualification)\n",
    "\n",
    "        display_df = display_df.reindex(columns=[\"Position\",\n",
    "                                                 \"Name\",\n",
    "                                                 \"Qualification\",\n",
    "                                                 \"Total Score\",\n",
    "                                                 \"Employment_Status\",\n",
    "                                                 \"Native_language\",\n",
    "                                                 \"Work_availability\",\n",
    "                                                 \"English_proficiency\",\n",
    "                                                 \"CV_Link\",\n",
    "                                                 \"Email\",\n",
    "                                                 \"Timestamp\"])\n",
    "\n",
    "        top10 = display_df.head(10)\n",
    "\n",
    "        html_output = top10.to_html(index=False)\n",
    "        styled_html_output = f'<div style=\"overflow-x:auto;\"><style>.dataframe tr {{ height: 25px; }}</style>{html_output}</div>'\n",
    "        display(HTML(styled_html_output))\n",
    "\n",
    "        export_button = widgets.Button(description=\"Export as Excel File\")\n",
    "        display(export_button)\n",
    "\n",
    "        def export_as_excel_file(_):\n",
    "            ph_time = timezone(timedelta(hours=8))\n",
    "            current_datetime = datetime.now(ph_time).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "            directory = \"/content/\"\n",
    "            # Sanitize the language for use in the filename\n",
    "            language_sanitized = sanitize_for_filename(language)\n",
    "            filename = f\"{position.replace('/', '_')}_{employment_status}_{language_sanitized}_{work}_{proficiency}_{current_datetime}.xlsx\"\n",
    "            filepath = os.path.join(directory, filename)\n",
    "\n",
    "            top10.to_excel(filepath, index=False)\n",
    "\n",
    "        export_button.on_click(export_as_excel_file)\n",
    "    except Exception as e:\n",
    "        pass  # Suppress any errors\n",
    "\n",
    "# Link dropdown widgets to the display_dataframe function\n",
    "widgets.interact(display_dataframe, position=position_dropdown, employment_status=employment_status_dropdown,\n",
    "                 language=language_dropdown, work=work_dropdown, proficiency=proficiency_dropdown,\n",
    "                 score_filter=score_filter_dropdown)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "F3e11Q_VGqcc",
    "NioUnIPmFXSt"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
